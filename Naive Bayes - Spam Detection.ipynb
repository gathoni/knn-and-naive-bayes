{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Spam Detection\n",
    "<img src = \"https://www.easyspace.com/blog/wp-content/uploads/2019/03/spam-1.png\">\n",
    "\n",
    "#### Problem Statement\n",
    "<blockquote>Given the features in the dataset, using Naive Bayes Classifier, we are to determine whether an email is spam or not.</blockquote>\n",
    "\n",
    "#### Evaluation Metrics\n",
    "<blockquote>We will use the accuracy score and F1 score to evaluate the performance of our model.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Other libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <th>char_freq_%28</th>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <th>char_freq_%21</th>\n",
       "      <th>char_freq_%24</th>\n",
       "      <th>char_freq_%23</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_%3B  char_freq_%28  \\\n",
       "0             0.00            0.00  ...           0.00          0.000   \n",
       "1             0.00            0.94  ...           0.00          0.132   \n",
       "2             0.64            0.25  ...           0.01          0.143   \n",
       "3             0.31            0.63  ...           0.00          0.137   \n",
       "4             0.31            0.63  ...           0.00          0.135   \n",
       "\n",
       "   char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23  \\\n",
       "0            0.0          0.778          0.000          0.000   \n",
       "1            0.0          0.372          0.180          0.048   \n",
       "2            0.0          0.276          0.184          0.010   \n",
       "3            0.0          0.137          0.000          0.000   \n",
       "4            0.0          0.135          0.000          0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  class  \n",
       "0                       278      1  \n",
       "1                      1028      1  \n",
       "2                      2259      1  \n",
       "3                       191      1  \n",
       "4                       191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call our dataframe 'spam'\n",
    "# \n",
    "spam = pd.read_csv('spambase_csv.csv')\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_freq_make</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.305358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_address</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_all</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>5.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_3d</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>42.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_our</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.380</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_over</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_remove</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_internet</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_order</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_mail</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.160</td>\n",
       "      <td>18.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_receive</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.059824</td>\n",
       "      <td>0.201545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_will</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.541702</td>\n",
       "      <td>0.861698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.800</td>\n",
       "      <td>9.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_people</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.093930</td>\n",
       "      <td>0.301036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_report</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.058626</td>\n",
       "      <td>0.335184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_addresses</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.049205</td>\n",
       "      <td>0.258843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_free</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.248848</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_business</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.142586</td>\n",
       "      <td>0.444055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_email</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.184745</td>\n",
       "      <td>0.531122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_you</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>1.662100</td>\n",
       "      <td>1.775481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.310</td>\n",
       "      <td>2.640</td>\n",
       "      <td>18.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_credit</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.085577</td>\n",
       "      <td>0.509767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_your</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.809761</td>\n",
       "      <td>1.200810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.220</td>\n",
       "      <td>1.270</td>\n",
       "      <td>11.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_font</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.121202</td>\n",
       "      <td>1.025756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_000</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.101645</td>\n",
       "      <td>0.350286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_money</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.094269</td>\n",
       "      <td>0.442636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_hp</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.549504</td>\n",
       "      <td>1.671349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_hpl</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.265384</td>\n",
       "      <td>0.886955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_george</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.767305</td>\n",
       "      <td>3.367292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>33.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_650</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.124845</td>\n",
       "      <td>0.538576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_lab</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.098915</td>\n",
       "      <td>0.593327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_labs</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.102852</td>\n",
       "      <td>0.456682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_telnet</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.064753</td>\n",
       "      <td>0.403393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_857</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.047048</td>\n",
       "      <td>0.328559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_data</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.097229</td>\n",
       "      <td>0.555907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_415</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.047835</td>\n",
       "      <td>0.329445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_85</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.105412</td>\n",
       "      <td>0.532260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_technology</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.402623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_1999</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.136953</td>\n",
       "      <td>0.423451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_parts</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.220651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_pm</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.078629</td>\n",
       "      <td>0.434672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_direct</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.064834</td>\n",
       "      <td>0.349916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_cs</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.043667</td>\n",
       "      <td>0.361205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_meeting</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.132339</td>\n",
       "      <td>0.766819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_original</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.046099</td>\n",
       "      <td>0.223812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_project</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.079196</td>\n",
       "      <td>0.621976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_re</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.301224</td>\n",
       "      <td>1.011687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.110</td>\n",
       "      <td>21.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_edu</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.179824</td>\n",
       "      <td>0.911119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_table</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.076274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_freq_conference</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.285735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_%28</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.188</td>\n",
       "      <td>9.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_%21</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>32.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_%24</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>6.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_freq_%23</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>19.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.588</td>\n",
       "      <td>2.276</td>\n",
       "      <td>3.706</td>\n",
       "      <td>1102.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>9989.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.000</td>\n",
       "      <td>95.000</td>\n",
       "      <td>266.000</td>\n",
       "      <td>15841.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>0.394045</td>\n",
       "      <td>0.488698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count        mean         std  min     25%  \\\n",
       "word_freq_make              4601.0    0.104553    0.305358  0.0   0.000   \n",
       "word_freq_address           4601.0    0.213015    1.290575  0.0   0.000   \n",
       "word_freq_all               4601.0    0.280656    0.504143  0.0   0.000   \n",
       "word_freq_3d                4601.0    0.065425    1.395151  0.0   0.000   \n",
       "word_freq_our               4601.0    0.312223    0.672513  0.0   0.000   \n",
       "word_freq_over              4601.0    0.095901    0.273824  0.0   0.000   \n",
       "word_freq_remove            4601.0    0.114208    0.391441  0.0   0.000   \n",
       "word_freq_internet          4601.0    0.105295    0.401071  0.0   0.000   \n",
       "word_freq_order             4601.0    0.090067    0.278616  0.0   0.000   \n",
       "word_freq_mail              4601.0    0.239413    0.644755  0.0   0.000   \n",
       "word_freq_receive           4601.0    0.059824    0.201545  0.0   0.000   \n",
       "word_freq_will              4601.0    0.541702    0.861698  0.0   0.000   \n",
       "word_freq_people            4601.0    0.093930    0.301036  0.0   0.000   \n",
       "word_freq_report            4601.0    0.058626    0.335184  0.0   0.000   \n",
       "word_freq_addresses         4601.0    0.049205    0.258843  0.0   0.000   \n",
       "word_freq_free              4601.0    0.248848    0.825792  0.0   0.000   \n",
       "word_freq_business          4601.0    0.142586    0.444055  0.0   0.000   \n",
       "word_freq_email             4601.0    0.184745    0.531122  0.0   0.000   \n",
       "word_freq_you               4601.0    1.662100    1.775481  0.0   0.000   \n",
       "word_freq_credit            4601.0    0.085577    0.509767  0.0   0.000   \n",
       "word_freq_your              4601.0    0.809761    1.200810  0.0   0.000   \n",
       "word_freq_font              4601.0    0.121202    1.025756  0.0   0.000   \n",
       "word_freq_000               4601.0    0.101645    0.350286  0.0   0.000   \n",
       "word_freq_money             4601.0    0.094269    0.442636  0.0   0.000   \n",
       "word_freq_hp                4601.0    0.549504    1.671349  0.0   0.000   \n",
       "word_freq_hpl               4601.0    0.265384    0.886955  0.0   0.000   \n",
       "word_freq_george            4601.0    0.767305    3.367292  0.0   0.000   \n",
       "word_freq_650               4601.0    0.124845    0.538576  0.0   0.000   \n",
       "word_freq_lab               4601.0    0.098915    0.593327  0.0   0.000   \n",
       "word_freq_labs              4601.0    0.102852    0.456682  0.0   0.000   \n",
       "word_freq_telnet            4601.0    0.064753    0.403393  0.0   0.000   \n",
       "word_freq_857               4601.0    0.047048    0.328559  0.0   0.000   \n",
       "word_freq_data              4601.0    0.097229    0.555907  0.0   0.000   \n",
       "word_freq_415               4601.0    0.047835    0.329445  0.0   0.000   \n",
       "word_freq_85                4601.0    0.105412    0.532260  0.0   0.000   \n",
       "word_freq_technology        4601.0    0.097477    0.402623  0.0   0.000   \n",
       "word_freq_1999              4601.0    0.136953    0.423451  0.0   0.000   \n",
       "word_freq_parts             4601.0    0.013201    0.220651  0.0   0.000   \n",
       "word_freq_pm                4601.0    0.078629    0.434672  0.0   0.000   \n",
       "word_freq_direct            4601.0    0.064834    0.349916  0.0   0.000   \n",
       "word_freq_cs                4601.0    0.043667    0.361205  0.0   0.000   \n",
       "word_freq_meeting           4601.0    0.132339    0.766819  0.0   0.000   \n",
       "word_freq_original          4601.0    0.046099    0.223812  0.0   0.000   \n",
       "word_freq_project           4601.0    0.079196    0.621976  0.0   0.000   \n",
       "word_freq_re                4601.0    0.301224    1.011687  0.0   0.000   \n",
       "word_freq_edu               4601.0    0.179824    0.911119  0.0   0.000   \n",
       "word_freq_table             4601.0    0.005444    0.076274  0.0   0.000   \n",
       "word_freq_conference        4601.0    0.031869    0.285735  0.0   0.000   \n",
       "char_freq_%3B               4601.0    0.038575    0.243471  0.0   0.000   \n",
       "char_freq_%28               4601.0    0.139030    0.270355  0.0   0.000   \n",
       "char_freq_%5B               4601.0    0.016976    0.109394  0.0   0.000   \n",
       "char_freq_%21               4601.0    0.269071    0.815672  0.0   0.000   \n",
       "char_freq_%24               4601.0    0.075811    0.245882  0.0   0.000   \n",
       "char_freq_%23               4601.0    0.044238    0.429342  0.0   0.000   \n",
       "capital_run_length_average  4601.0    5.191515   31.729449  1.0   1.588   \n",
       "capital_run_length_longest  4601.0   52.172789  194.891310  1.0   6.000   \n",
       "capital_run_length_total    4601.0  283.289285  606.347851  1.0  35.000   \n",
       "class                       4601.0    0.394045    0.488698  0.0   0.000   \n",
       "\n",
       "                               50%      75%        max  \n",
       "word_freq_make               0.000    0.000      4.540  \n",
       "word_freq_address            0.000    0.000     14.280  \n",
       "word_freq_all                0.000    0.420      5.100  \n",
       "word_freq_3d                 0.000    0.000     42.810  \n",
       "word_freq_our                0.000    0.380     10.000  \n",
       "word_freq_over               0.000    0.000      5.880  \n",
       "word_freq_remove             0.000    0.000      7.270  \n",
       "word_freq_internet           0.000    0.000     11.110  \n",
       "word_freq_order              0.000    0.000      5.260  \n",
       "word_freq_mail               0.000    0.160     18.180  \n",
       "word_freq_receive            0.000    0.000      2.610  \n",
       "word_freq_will               0.100    0.800      9.670  \n",
       "word_freq_people             0.000    0.000      5.550  \n",
       "word_freq_report             0.000    0.000     10.000  \n",
       "word_freq_addresses          0.000    0.000      4.410  \n",
       "word_freq_free               0.000    0.100     20.000  \n",
       "word_freq_business           0.000    0.000      7.140  \n",
       "word_freq_email              0.000    0.000      9.090  \n",
       "word_freq_you                1.310    2.640     18.750  \n",
       "word_freq_credit             0.000    0.000     18.180  \n",
       "word_freq_your               0.220    1.270     11.110  \n",
       "word_freq_font               0.000    0.000     17.100  \n",
       "word_freq_000                0.000    0.000      5.450  \n",
       "word_freq_money              0.000    0.000     12.500  \n",
       "word_freq_hp                 0.000    0.000     20.830  \n",
       "word_freq_hpl                0.000    0.000     16.660  \n",
       "word_freq_george             0.000    0.000     33.330  \n",
       "word_freq_650                0.000    0.000      9.090  \n",
       "word_freq_lab                0.000    0.000     14.280  \n",
       "word_freq_labs               0.000    0.000      5.880  \n",
       "word_freq_telnet             0.000    0.000     12.500  \n",
       "word_freq_857                0.000    0.000      4.760  \n",
       "word_freq_data               0.000    0.000     18.180  \n",
       "word_freq_415                0.000    0.000      4.760  \n",
       "word_freq_85                 0.000    0.000     20.000  \n",
       "word_freq_technology         0.000    0.000      7.690  \n",
       "word_freq_1999               0.000    0.000      6.890  \n",
       "word_freq_parts              0.000    0.000      8.330  \n",
       "word_freq_pm                 0.000    0.000     11.110  \n",
       "word_freq_direct             0.000    0.000      4.760  \n",
       "word_freq_cs                 0.000    0.000      7.140  \n",
       "word_freq_meeting            0.000    0.000     14.280  \n",
       "word_freq_original           0.000    0.000      3.570  \n",
       "word_freq_project            0.000    0.000     20.000  \n",
       "word_freq_re                 0.000    0.110     21.420  \n",
       "word_freq_edu                0.000    0.000     22.050  \n",
       "word_freq_table              0.000    0.000      2.170  \n",
       "word_freq_conference         0.000    0.000     10.000  \n",
       "char_freq_%3B                0.000    0.000      4.385  \n",
       "char_freq_%28                0.065    0.188      9.752  \n",
       "char_freq_%5B                0.000    0.000      4.081  \n",
       "char_freq_%21                0.000    0.315     32.478  \n",
       "char_freq_%24                0.000    0.052      6.003  \n",
       "char_freq_%23                0.000    0.000     19.829  \n",
       "capital_run_length_average   2.276    3.706   1102.500  \n",
       "capital_run_length_longest  15.000   43.000   9989.000  \n",
       "capital_run_length_total    95.000  266.000  15841.000  \n",
       "class                        0.000    1.000      1.000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the describe function to get the general description of the data.\n",
    "spam.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the spambase data:(4601, 58)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the datasets\n",
    "print (\"The shape of the spambase data:\"+ str(spam.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      "word_freq_make                4601 non-null float64\n",
      "word_freq_address             4601 non-null float64\n",
      "word_freq_all                 4601 non-null float64\n",
      "word_freq_3d                  4601 non-null float64\n",
      "word_freq_our                 4601 non-null float64\n",
      "word_freq_over                4601 non-null float64\n",
      "word_freq_remove              4601 non-null float64\n",
      "word_freq_internet            4601 non-null float64\n",
      "word_freq_order               4601 non-null float64\n",
      "word_freq_mail                4601 non-null float64\n",
      "word_freq_receive             4601 non-null float64\n",
      "word_freq_will                4601 non-null float64\n",
      "word_freq_people              4601 non-null float64\n",
      "word_freq_report              4601 non-null float64\n",
      "word_freq_addresses           4601 non-null float64\n",
      "word_freq_free                4601 non-null float64\n",
      "word_freq_business            4601 non-null float64\n",
      "word_freq_email               4601 non-null float64\n",
      "word_freq_you                 4601 non-null float64\n",
      "word_freq_credit              4601 non-null float64\n",
      "word_freq_your                4601 non-null float64\n",
      "word_freq_font                4601 non-null float64\n",
      "word_freq_000                 4601 non-null float64\n",
      "word_freq_money               4601 non-null float64\n",
      "word_freq_hp                  4601 non-null float64\n",
      "word_freq_hpl                 4601 non-null float64\n",
      "word_freq_george              4601 non-null float64\n",
      "word_freq_650                 4601 non-null float64\n",
      "word_freq_lab                 4601 non-null float64\n",
      "word_freq_labs                4601 non-null float64\n",
      "word_freq_telnet              4601 non-null float64\n",
      "word_freq_857                 4601 non-null float64\n",
      "word_freq_data                4601 non-null float64\n",
      "word_freq_415                 4601 non-null float64\n",
      "word_freq_85                  4601 non-null float64\n",
      "word_freq_technology          4601 non-null float64\n",
      "word_freq_1999                4601 non-null float64\n",
      "word_freq_parts               4601 non-null float64\n",
      "word_freq_pm                  4601 non-null float64\n",
      "word_freq_direct              4601 non-null float64\n",
      "word_freq_cs                  4601 non-null float64\n",
      "word_freq_meeting             4601 non-null float64\n",
      "word_freq_original            4601 non-null float64\n",
      "word_freq_project             4601 non-null float64\n",
      "word_freq_re                  4601 non-null float64\n",
      "word_freq_edu                 4601 non-null float64\n",
      "word_freq_table               4601 non-null float64\n",
      "word_freq_conference          4601 non-null float64\n",
      "char_freq_%3B                 4601 non-null float64\n",
      "char_freq_%28                 4601 non-null float64\n",
      "char_freq_%5B                 4601 non-null float64\n",
      "char_freq_%21                 4601 non-null float64\n",
      "char_freq_%24                 4601 non-null float64\n",
      "char_freq_%23                 4601 non-null float64\n",
      "capital_run_length_average    4601 non-null float64\n",
      "capital_run_length_longest    4601 non-null int64\n",
      "capital_run_length_total      4601 non-null int64\n",
      "class                         4601 non-null int64\n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (spam.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                0\n",
       "word_freq_address             0\n",
       "word_freq_all                 0\n",
       "word_freq_3d                  0\n",
       "word_freq_our                 0\n",
       "word_freq_over                0\n",
       "word_freq_remove              0\n",
       "word_freq_internet            0\n",
       "word_freq_order               0\n",
       "word_freq_mail                0\n",
       "word_freq_receive             0\n",
       "word_freq_will                0\n",
       "word_freq_people              0\n",
       "word_freq_report              0\n",
       "word_freq_addresses           0\n",
       "word_freq_free                0\n",
       "word_freq_business            0\n",
       "word_freq_email               0\n",
       "word_freq_you                 0\n",
       "word_freq_credit              0\n",
       "word_freq_your                0\n",
       "word_freq_font                0\n",
       "word_freq_000                 0\n",
       "word_freq_money               0\n",
       "word_freq_hp                  0\n",
       "word_freq_hpl                 0\n",
       "word_freq_george              0\n",
       "word_freq_650                 0\n",
       "word_freq_lab                 0\n",
       "word_freq_labs                0\n",
       "word_freq_telnet              0\n",
       "word_freq_857                 0\n",
       "word_freq_data                0\n",
       "word_freq_415                 0\n",
       "word_freq_85                  0\n",
       "word_freq_technology          0\n",
       "word_freq_1999                0\n",
       "word_freq_parts               0\n",
       "word_freq_pm                  0\n",
       "word_freq_direct              0\n",
       "word_freq_cs                  0\n",
       "word_freq_meeting             0\n",
       "word_freq_original            0\n",
       "word_freq_project             0\n",
       "word_freq_re                  0\n",
       "word_freq_edu                 0\n",
       "word_freq_table               0\n",
       "word_freq_conference          0\n",
       "char_freq_%3B                 0\n",
       "char_freq_%28                 0\n",
       "char_freq_%5B                 0\n",
       "char_freq_%21                 0\n",
       "char_freq_%24                 0\n",
       "char_freq_%23                 0\n",
       "capital_run_length_average    0\n",
       "capital_run_length_longest    0\n",
       "capital_run_length_total      0\n",
       "class                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "spam.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>The data has no missing values</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tidying the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence:  True\n",
      "Count:  391\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates in the data\n",
    "print('Presence: ',spam.duplicated(keep = 'first').any())\n",
    "print('Count: ',spam.duplicated(keep = 'first').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with duplicate values while keeping the first occurence of the record.\n",
    "\n",
    "spam.drop_duplicates(keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datase has  4210 rows and  58 columns\n"
     ]
    }
   ],
   "source": [
    "# Shape of the dataset after dropping duplicated rows\n",
    "\n",
    "print('The datase has ', spam.shape[0], 'rows and ', spam.shape[1], 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. EDA\n",
    "#### Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Spam vs Non_Spam Emails')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the target variable \n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"class\", data=spam)\n",
    "ax.set_title('Spam vs Non_Spam Emails', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>we have more non spam emails compared to spam emails.</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample does not look Gaussian\n"
     ]
    }
   ],
   "source": [
    "# First we will verify whether the features are normally distriibuted or not.\n",
    "\n",
    "# Using the shapiro test, we will test the for normality on the features of our data\n",
    "# Use a for loop to iterate through all the columns systematically.\n",
    "\n",
    "# importing the shapiro function\n",
    "from scipy.stats import shapiro \n",
    "\n",
    "for i in spam.columns:\n",
    "\n",
    "  stat, p = shapiro(spam[i])             # testing for normality\n",
    "\n",
    "# interpreting the results\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Sample looks Gaussian')\n",
    "else:\n",
    "    print('Sample does not look Gaussian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>The data is not normal and so we will have to normalize the data before we do our clasification</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implementing the Solution\n",
    "#### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4210, 57)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into dependent and independent sets.\n",
    "X = spam.drop('class', axis = 1)\n",
    "y = spam['class']\n",
    "\n",
    "# Splitting our data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes\n",
    "This type of classifier makes the assumption of normal distribution, thus can be best used in cases when all our features are continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the features \n",
    "norm = Normalizer().fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train our model and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training our model\n",
    "# \n",
    "gnb = GaussianNB()  \n",
    "model = gnb.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.85       483\n",
      "           1       0.75      0.97      0.84       359\n",
      "\n",
      "    accuracy                           0.85       842\n",
      "   macro avg       0.86      0.86      0.85       842\n",
      "weighted avg       0.88      0.85      0.85       842\n",
      "\n",
      "[[365 118]\n",
      " [ 11 348]]\n",
      "The accuracy : 0.8467933491686461\n",
      "F1 Score : 0.8436363636363636\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the predictions made by the model\n",
    "\n",
    "# 1. Using Classification report\n",
    "print(classification_report(y_test, predicted))\n",
    "\n",
    "# 2. Using  the accuracy score\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "print('The accuracy :',accuracy_score(predicted,y_test))\n",
    "print('F1 Score :',f1_score(predicted,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>Our gaussian model has an f1 score of 84% and an accuracy score of 85% </blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       483\n",
      "           1       0.79      0.74      0.76       359\n",
      "\n",
      "    accuracy                           0.80       842\n",
      "   macro avg       0.80      0.80      0.80       842\n",
      "weighted avg       0.80      0.80      0.80       842\n",
      "\n",
      "[[411  72]\n",
      " [ 93 266]]\n",
      "The accuracy : 0.8040380047505938\n",
      "F1 Score : 0.763271162123386\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset 80,20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Training the model.\n",
    "# Splitting the data into train and test sets\n",
    "\n",
    "mnb = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_pred1 = mnb.predict(X_test)\n",
    "\n",
    "# Evaluating the predictions made by the model\n",
    "\n",
    "# 1. Using Classification report\n",
    "print(classification_report(y_test, y_pred1))\n",
    "\n",
    "\n",
    "# 2. Using  the accuracy score\n",
    "print(confusion_matrix(y_test, y_pred1))\n",
    "print('The accuracy :',accuracy_score(y_pred1,y_test))\n",
    "print('F1 Score :',f1_score(y_pred1,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>The multinomial NB model has an f1 score of 76.3% and an accuracy score of 80.4% </blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       737\n",
      "           1       0.89      0.83      0.86       526\n",
      "\n",
      "    accuracy                           0.89      1263\n",
      "   macro avg       0.89      0.88      0.88      1263\n",
      "weighted avg       0.89      0.89      0.89      1263\n",
      "\n",
      "[[680  57]\n",
      " [ 87 439]]\n",
      "The accuracy : 0.8859857482185273\n",
      "F1 Score : 0.8590998043052838\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset 80,20\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 55)\n",
    "\n",
    "# Training the model.\n",
    "# Splitting the data into train and test sets\n",
    "\n",
    "bnb = BernoulliNB().fit(X_train, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_pred2 = bnb.predict(X_test)\n",
    "\n",
    "# Evaluating the predictions made by the model\n",
    "\n",
    "# 1. Using Classification report\n",
    "print(classification_report(y_test, y_pred2))\n",
    "\n",
    "\n",
    "# 2. Using  the accuracy score\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "print('The accuracy :',accuracy_score(y_pred2,y_test))\n",
    "print('F1 Score :',f1_score(y_pred2,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>The Bernoulli NB model has an f1 score of 86% and an accuracy score of 89% </blockquote>\n",
    "\n",
    "<blockquote>The Bernoulli model has yielded the highest score of the 3 models </blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenging the Solution\n",
    "\n",
    "#### Using Support Vector Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Polynomial is: 0.7612826603325415 and the f1 score is: 0.6256983240223464\n",
      "The accuracy score of Linear     is: 0.9216152019002375 and the f1 score is: 0.905982905982906\n",
      "The accuracy score of Rbf        is: 0.9180522565320665 and the f1 score is: 0.9012875536480687\n"
     ]
    }
   ],
   "source": [
    "# Fitting the Support Vector Classifier\n",
    "# Splitting the data\n",
    "\n",
    "# Selecting the independent variables and the target variable\n",
    "x = spam.drop('class', axis = 1)\n",
    "y = spam['class']\n",
    "\n",
    "# Instantiating and creating a list of models for iteration\n",
    "#\n",
    "from sklearn.svm import SVC\n",
    "poly = SVC(kernel='poly')\n",
    "linear = SVC(kernel = 'linear')\n",
    "rbf = SVC(kernel ='rbf')\n",
    "\n",
    "# Creating a list of the models and model names\n",
    "#\n",
    "models = [poly, linear, rbf]\n",
    "model_names = ['Polynomial', 'Linear', 'Rbf']\n",
    "\n",
    "# Creating a function that trains a model and returns its accuracy together with the model\n",
    "#\n",
    "def predictor(model, x, y):\n",
    "  # Splitting the data into training and testing sets\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "  \n",
    "  # Standardising the data\n",
    "  from sklearn.preprocessing import StandardScaler\n",
    "  sc = StandardScaler()\n",
    "  x_train = sc.fit_transform(x_train)\n",
    "  x_test = sc.transform(x_test)\n",
    "  \n",
    "  # Training the model and making predictions\n",
    "  model.fit(x_train, y_train)\n",
    "  y_pred = model.predict(x_test)\n",
    "  \n",
    "  # Measuring the accuracy of the model\n",
    "  f1 = f1_score(y_test, y_pred)\n",
    "  acc = accuracy_score(y_test, y_pred)\n",
    "  \n",
    "  # Returning the accuracy and the model\n",
    "  return acc, f1, model\n",
    "\n",
    "# Getting the accuracies of the models  using a for loop\n",
    "#\n",
    "for model, name in zip(models, model_names):\n",
    "  print(f'The accuracy score of {name:<10} is: {predictor(model, x, y)[0]} and the f1 score is: {predictor(model, x, y)[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>We observe that SVM Model using the linear kernel has yielded an F1 score of 91% and an accuracy of 92% which is better than the Naive Bayes Classifier for spam detection</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The Bernoulli NB is the best model since it yielded both the best Accuracy and Recall scores.\n",
    "\n",
    "Optimizing the model is very essential:\n",
    "<li>Scaling or normalizing the features</li>\n",
    "<li>Reducing the data dimensions</li>\n",
    "<li>Increasing the test size for a large dataset.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
